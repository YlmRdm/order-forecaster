{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b5ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9fa48",
   "metadata": {},
   "source": [
    "### Regressive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_supervised(data):\n",
    "    supervised = data.copy()\n",
    "    \n",
    "    # Creating column for each lag\n",
    "    for i in range(1,13):\n",
    "        col_name = 'lag_' + str(i)\n",
    "        supervised[col_name] = supervised['sales_diff'].shift(i)\n",
    "    \n",
    "    # Dropping null values\n",
    "    supervised = supervised.dropna().reset_index(drop=True)\n",
    "    \n",
    "    supervised.to_csv('../data/input/model.csv', index=False)\n",
    "    \n",
    "    return supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccbf8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary = pd.read_csv('../data/input/stationary.csv')\n",
    "model_df = generate_supervised(stationary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610cd71",
   "metadata": {},
   "source": [
    "### ARIMA Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arima_data(data):\n",
    "    dt_data = data.set_index('orderDate').drop('sales', axis=1)\n",
    "    dt_data.dropna(axis=0)\n",
    "    \n",
    "    dt_data.to_csv('../data/output/arima.csv')\n",
    "    \n",
    "    return dt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6513f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_df = generate_arima_data(stationary)\n",
    "datetime_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d909d678",
   "metadata": {},
   "source": [
    "#### Loading the ARIMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26957690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    return pd.read_csv('../data/output/arima.csv').set_index('orderDate')\n",
    "\n",
    "arm_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b30d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_data.index = pd.to_datetime(arm_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb0d636",
   "metadata": {},
   "source": [
    "### SARIMAX Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c51f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(data):\n",
    "    \n",
    "    model_scores = {}\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(data.sales_diff[-12:], data.forecast[-12:]))\n",
    "    mae = mean_absolute_error(data.sales_diff[-12:], data.forecast[-12:])\n",
    "    r2 = r2_score(data.sales_diff[-12:], data.forecast[-12:])\n",
    "    model_scores['ARIMA'] = [rmse, mae, r2]\n",
    "    \n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "    \n",
    "    pickle.dump(model_scores, open( \"arima_model_scores.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarimax_model(data):\n",
    "    # Model\n",
    "    sar = sm.tsa.statespace.SARIMAX(arm_data.sales_diff, order=(12,0,0), seasonal_order=(0,1,0,12), trend='c').fit()\n",
    "\n",
    "    # Predictions\n",
    "    start, end, dynamic = 40, 100, 7\n",
    "    data['forecast'] = sar.predict(start=start, end=end, dynamic=dynamic) \n",
    "    pred_df = data.forecast[start+dynamic:end]\n",
    "    \n",
    "    data[['sales_diff', 'forecast']].plot(color=['mediumblue', 'Red'])\n",
    "    \n",
    "    get_scores(data)\n",
    "\n",
    "    return sar, data, pred_df\n",
    "\n",
    "sar, arm_data, predictions = sarimax_model(arm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf963f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar.plot_diagnostics(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e7530d",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(prediction_df):\n",
    "    \n",
    "    #load in original dataframe without scaling applied\n",
    "    original_df = pd.read_csv('../data/input/train.csv')\n",
    "    original_df.date = original_df.date.apply(lambda x: str(x)[:-3])\n",
    "    original_df = original_df.groupby('orderDate')['sales'].sum().reset_index()\n",
    "    original_df.date = pd.to_datetime(original_df.date)\n",
    "    \n",
    "    #create dataframe that shows the predicted sales\n",
    "    result_list = []\n",
    "    sales_dates = list(original_df[-13:].date)\n",
    "    act_sales = list(original_df[-13:].sales)\n",
    "    \n",
    "    for index in range(0,len(prediction_df)):\n",
    "        result_dict = {}\n",
    "        result_dict['pred_value'] = int(prediction_df[index] + act_sales[index])\n",
    "        result_dict['date'] = sales_dates[index+1]\n",
    "        result_list.append(result_dict)\n",
    "        \n",
    "    df_result = pd.DataFrame(result_list)\n",
    "    \n",
    "    return df_result, original_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518fedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, original_df, model_name):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    sns.lineplot(original_df.date, original_df.sales, data=original_df, ax=ax, \n",
    "                label='Original', color='mediumblue')\n",
    "    sns.lineplot(results.date, results.pred_value, data=results, ax=ax, \n",
    "                 label='Predicted', color='Red')\n",
    "    \n",
    "    ax.set(xlabel = \"Date\",\n",
    "           ylabel = \"Orders\",\n",
    "           title = f\"{model_name} Order Forecaster\")\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    sns.despine()\n",
    "    \n",
    "\n",
    "    plt.savefig(f'../model_output/{model_name}_forecast.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91183f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df, original_df = predict_df(predictions)\n",
    "plot_results(prediction_df, original_df, 'arima')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf95e3f074dbca86fcbfe00141dfe3dcf5fe8b17306f655f7952e7fdffcad5e4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
